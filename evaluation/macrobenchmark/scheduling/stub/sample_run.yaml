accuracy: 0.5895164124218815
adaptive_batch_size: 1
alphas:
- 1.5
- 1.75
- 2
- 2.5
- 3
- 4
- 5
- 6
- 8
- 16
- 32
- 64
batch_size: 160
best_alpha: 64.0
delta: 1.0e-09
device: cuda
dp: 1
dp_eval: 0
dropout: 0.25
dynamic_clipping: 0
embedding_dim: 100
epsilon: 0.49888296567890833
hidden_dim: 100
hidden_dim_1: 185
hidden_dim_2: 150
learning_rate: 0.01
learning_rate_scheduler: 1
loss: 1.6545968994079345
max_grad_norm: 1.0
max_text_len: 60
model: feedforward
n_blocks: 100
n_blocks_test: 200
n_epochs: 15
n_trainable_parameters: 48246
n_workers: 6
noise: 4.282418212890625
per_layer_clipping: 0
rdp_epsilons:
- 0.003894617377537186
- 0.004544120544745451
- 0.005193738160329665
- 0.006493316971045715
- 0.0077933541384930805
- 0.010394804874002263
- 0.012998092993436192
- 0.015603221129266204
- 0.020819008009987178
- 0.04175628683116831
- 0.08399116655612908
- 0.1699422381083304
target_epsilon: 0.5
task: product
test_size: 39692
timeframe_days: 0
total_time: 22.891680240631104
train_size: 25748
training_accuracy_epochs:
- 0.4227734433952719
- 0.4811328198760748
- 0.5535156343132257
- 0.5646484469994902
- 0.5727343866601586
- 0.5745703248307109
- 0.5789062624797225
- 0.5796875139698386
- 0.5860156370326877
- 0.5895312607288361
- 0.5890625141561031
- 0.5903906367719174
- 0.5910547003149986
- 0.591210949793458
- 0.5914062613621354
training_loss_epochs:
- 2.036991549283266
- 1.7381136812269689
- 1.578173902630806
- 1.5565402902662755
- 1.6030811630189419
- 1.6479368910193444
- 1.6552979245781898
- 1.7415583558380603
- 1.6939784593880176
- 1.6607449427247047
- 1.6478415988385677
- 1.6340246133506298
- 1.6200220309197904
- 1.626873006671667
- 1.6240474306046964
training_time: 19.038874864578247
user_level: 0
validation_accuracy_epochs:
- 0.43172919498868734
- 0.5464403191244745
- 0.5624589374266475
- 0.5641840208007629
- 0.573555600212281
- 0.5728847334183842
- 0.5742059271019625
- 0.573370770517602
- 0.5841114567704948
- 0.5864389488495976
- 0.5867401533816234
- 0.5873904817075615
- 0.5870755860604435
- 0.5873699468302439
- 0.5871303523161325
validation_loss_epochs:
- 2.0458452026528047
- 1.6101174368915787
- 1.585701673863882
- 1.5628263533833515
- 1.6328541686735958
- 1.6030440919370537
- 1.6789415428437382
- 1.7707777698355984
- 1.7073875062436943
- 1.6833506722048104
- 1.6847833883331482
- 1.6613380219562943
- 1.6730629923831986
- 1.6753978786698307
- 1.675001940095281
virtual_batch_multiplier: 0
vocab_size: 10000
